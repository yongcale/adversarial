
# Reference List

## Adversarial Example/Training
* [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)
* [Breaking Linear Classifiers on ImageNet](http://karpathy.github.io/2015/03/30/breaking-convnets/)
* [Practical black-box attacks against machine learning](https://arxiv.org/abs/1602.02697)
* [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199)
* [Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images](https://arxiv.org/abs/1412.1897)
* [Delving into Transferable Adversarial Examples and Black-box attacks](https://arxiv.org/abs/1611.02770)
* [Delving into adversarial attacks on deep policies](https://arxiv.org/abs/1705.06452)
* [Synthesizing Robust Adversarial Examples](https://arxiv.org/abs/1707.07397)
* [Adversarial Examples for Semantic Image Segmentation](https://arxiv.org/abs/1703.01101)
* [Universal Adversarial Perturbations Against Semantic Image Segmentation](https://arxiv.org/abs/1704.05712)
* [Adversarial Examples for Semantic Segmentation and Object Detection](https://arxiv.org/pdf/1703.08603.pdf)
* [Universal adversarial perturbations](https://arxiv.org/abs/1610.08401)
* [Learning to Protect Communications with Adversarial Neural Cryptography](https://arxiv.org/abs/1610.06918v1)
* [Adversarial Attacks on Neural Network Policies](https://arxiv.org/abs/1702.02284)  (http://rll.berkeley.edu/adversarial/)
* [Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/abs/1705.07204)
* [Standard implementation of attacks, for adversarial training and reproducible benchmarks](https://github.com/tensorflow/cleverhans)
* [SafetyNet: Detecting and Rejecting Adversarial Examples Robustly](https://arxiv.org/abs/1704.00103)
* [Tactics of Adversarial Attack on Deep Reinforcement Learning Agents](https://arxiv.org/abs/1703.06748)
* [Detecting Adversarial Samples from Artifacts](https://arxiv.org/abs/1703.00410)
* [Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong](https://arxiv.org/abs/1706.04701)
* [Generating Adversarial Examples for Speech Recognition](http://web.stanford.edu/class/cs224s/reports/Dan_Iter.pdf)
---

##  GAN:  (https://github.com/hindupuravinash/the-gan-zoo)
* [AE-GAN: adversarial eliminating with GAN](https://arxiv.org/abs/1707.05474)
* [Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN](https://arxiv.org/abs/1702.05983v1)
* [Generative Adversarial Networks](https://arxiv.org/abs/1406.266)

---


## Ongoing Kaggle competition:
* https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack
* https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack
* https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack

---

## Blog on OpenAI:
* https://blog.openai.com/adversarial-example-research/
* https://blog.openai.com/robust-adversarial-inputs/

---

## Basics in Machine Learning

### CNN with TensorFlow
* [从零开始用TensorFlow搭建卷积神经网络](https://mp.weixin.qq.com/s/VlvQmrS7Qi2qq6fTBXKTYw)
* [卷积神经网络初学者指南](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650717691&idx=2&sn=3f0b66aa9706aae1a30b01309aa0214c&scene=21#wechat_redirect) 
* [卷积神经网络简介](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723520&idx=4&sn=8ee14dd052766ca3e0afa60dcbb65b2d&chksm=871b10beb06c99a81ef547319637a177142d33a40da5a85024fc6a3b623d60d3a7ac22e3efc3&scene=21#wechat_redirect)
* [长文揭秘图像处理和卷积神经网络架构](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650728746&idx=1&sn=61e9cb824501ec7c505eb464e8317915&chksm=871b2d54b06ca442bc049e97c97e117455fd31bd0fb0619be4592eebd0958c26e3c223bfbfe5&scene=21#wechat_redirect)

### Reinforcement Learning
* [Deep Reinforcement Learning 基础知识（DQN方面）](http://blog.csdn.net/songrotek/article/details/50580904) 
* [Udacity course "Deep Learning"](https://www.youtube.com/watch?v=iF8dRePlPUo&list=PLAwxTw4SYaPn_OWPFT9ulXLuQrImzHfOV)

### SDG - Stochastic Gradient Descent
* [各种梯度优化算法介绍（SGD Loss剧烈波动）](http://blog.csdn.net/chenzhi1992/article/details/52850759)
